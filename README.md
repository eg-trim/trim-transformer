# Trim Transformer

A linear-attention transformer implementation with KV caching.